{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"../../assets/htwlogo.svg\">\n",
    "\n",
    "# Exercise: Classification with FashionMNIST\n",
    "\n",
    "**Author**: _Erik Rodner_ (adapted from John Bosco)\n",
    "\n",
    "In the following notebook, we will learn our first convolutional neural network for image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some dependencies\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from collections import OrderedDict\n",
    "torch.set_printoptions(linewidth=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Defining the dataset\n",
    "\n",
    "We will use the FashionMNIST dataset. ``pytorch`` already contains some helper functions that download\n",
    "the dataset (if it is not available locally). Furthermore, the dataset splits are already given for training\n",
    "and testing. The ``transform`` parameter defines a function that takes an PIL image and preprocesses it to the input for the network. If you want to add pre-processing, you could use a compose statement and further operations: ``transforms.Compose([.., transforms.ToTensor()]``, but for now we simply transform it to a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(root=\"./\", download=True, \n",
    "                                              train=True,\n",
    "                                              transform=transforms.ToTensor())\n",
    "\n",
    "test_set = torchvision.datasets.FashionMNIST(root=\"./\", download=True, \n",
    "                                              train=False,\n",
    "                                              transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Now, let's define the data loader, as usual: batching and shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(train_set, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Let us take a single example and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a single batch\n",
    "sample = next(iter(data_loader))\n",
    "imgs, lbls = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a grid \n",
    "plt.figure(figsize=(15,10))\n",
    "grid = torchvision.utils.make_grid(nrow=20, tensor=imgs)\n",
    "print(f\"image tensor: {imgs.shape}\")\n",
    "print(f\"class labels: {lbls}\")\n",
    "plt.imshow(np.transpose(grid, axes=(1,2,0)), cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Additional helper functions\n",
    "\n",
    "Let's define some helper functions to compute all predictions on a given dataset and to count the number of correctly classified examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some helper functions\n",
    "def count_correct_samples(preds, labels):\n",
    "    \"\"\"function that returns the accuracy of our architecture\"\"\"\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "@torch.no_grad() # turn off gradients during inference for memory efficiency\n",
    "def get_all_preds(network, dataloader):\n",
    "    \"\"\"function to return the number of correct predictions across data set\"\"\"\n",
    "    all_preds = torch.tensor([])\n",
    "    all_labels = torch.tensor([])\n",
    "    for batch in dataloader:\n",
    "        images, labels = batch\n",
    "        preds = network(images) # get preds\n",
    "        all_preds = torch.cat((all_preds, preds), dim=0) # join along existing axis\n",
    "        all_labels = torch.cat((all_labels, labels), dim=0) # join along existing axis\n",
    "        \n",
    "    return all_preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Defining the model \n",
    "\n",
    "Similar to our *Where is Waldo* exercise, we define our model as an ``nn.Module``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "\n",
    "class Network(nn.Module): # extend nn.Module class of nn\n",
    "    def __init__(self):\n",
    "        super().__init__() # super class constructor\n",
    "        # The FasionMNIST dataset is grayscale, therefore we have an in_channels parameter\n",
    "        # of the first layer of 1\n",
    "        \n",
    "        self.layers = [\n",
    "             (\"conv1\", nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(5,5))),\n",
    "             (\"maxpool1\", nn.AvgPool2d(kernel_size=2, stride=2)),\n",
    "             (\"relu1\", nn.ReLU()),\n",
    "             (\"conv2\", nn.Conv2d(in_channels=1, out_channels=12, kernel_size=(5,5))),\n",
    "             (\"maxpool2\", nn.AvgPool2d(kernel_size=2, stride=2)),\n",
    "             (\"relu2\", nn.ReLU()),\n",
    "             # fully-connected part\n",
    "             (\"flatten\", nn.Flatten()),\n",
    "             (\"fc1\", nn.Linear(in_features=12*4*4, out_features=12)),\n",
    "             (\"relu3\", nn.ReLU()),\n",
    "             (\"fc2\", nn.Linear(in_features=12, out_features=6)),\n",
    "             (\"relu4\", nn.ReLU()),\n",
    "             (\"out\", nn.Linear(in_features=6, out_features=10)) ]\n",
    "        \n",
    "        self.seq = torch.nn.Sequential( OrderedDict(self.layers) )\n",
    "        \n",
    "        \n",
    "    def forward(self, t): # forward!\n",
    "        return self.seq(t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data loader and the batch size\n",
    "data_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Training optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Network() # init model\n",
    "optimizer = optim.Adam(lr=0.001, params=cnn_model.parameters())\n",
    "\n",
    "# train loop\n",
    "for epoch in range(5):\n",
    "    start_time = time.time()\n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        imgs, lbls = batch\n",
    "        preds = cnn_model(imgs) # get preds\n",
    "        loss = F.cross_entropy(preds, lbls) # compute loss\n",
    "        optimizer.zero_grad() # zero grads\n",
    "        loss.backward() # calculates gradients \n",
    "        optimizer.step() # update the weights\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_correct += count_correct_samples(preds, lbls)\n",
    "        accuracy = total_correct/len(train_set)\n",
    "    end_time = time.time() - start_time    \n",
    "    print(f\"Epoch no. {epoch+1}|training accuracy: {accuracy*100:.3f}% |total_loss: {total_loss} |epoch_duration: {end_time:.2f}sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Let's evaluate our classifier on the predefined test set. Define a data loader for convenience first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_test = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Now, get all predictions at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, labels = get_all_preds(cnn_model, data_loader_test)\n",
    "preds_discrete_np = np.array(preds.argmax(dim=1))\n",
    "labels_np = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Compute accuracies and the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(labels_np, preds_discrete_np)\n",
    "total_accuracy = np.sum(np.diag(cm))/len(labels_np)\n",
    "class_accuracies = np.diag(cm)/np.sum(cm, axis=1)\n",
    "print (f\"Standard accuracy: {total_accuracy*100:.2f}%\")\n",
    "print (f\"Class accuracies: {class_accuracies}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "... and display the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_set.classes)\n",
    "plt.figure(figsize=(20,10))\n",
    "disp.plot(ax=plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
